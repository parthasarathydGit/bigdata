{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notbook helps you get started with plotly on Spark using Python (pyspark) on CloudxLab.\n",
    "### This is loosely based on https://plot.ly/python/apache-spark/\n",
    "### It Also requires to signup with plotly. We are not endorsing plotly. We are just helping users to get started in learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PATH\n",
    "import os\n",
    "import sys\n",
    "os.environ[\"SPARK_HOME\"] = \"/usr/hdp/current/spark-client\"\n",
    "os.environ[\"PYLIB\"] = os.environ[\"SPARK_HOME\"] + \"/python/lib\"\n",
    "# In below two lines, use /usr/bin/python2.7 if you want to use Python 2 \n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"/usr/local/anaconda/bin/python\"\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/py4j-0.9-src.zip\")\n",
    "sys.path.insert(0, os.environ[\"PYLIB\"] +\"/pyspark.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The Project Gutenberg EBook of The Adventures of Sherlock Holmes', 'by Sir Arthur Conan Doyle', '(#15 in our series by Sir Arthur Conan Doyle)', '', 'Copyright laws are changing all over the world. Be sure to check the', 'copyright laws for your country before downloading or redistributing', 'this or any other Project Gutenberg eBook.', '', 'This header should be the first thing seen when viewing this Project', 'Gutenberg file.  Please do not remove it.  Do not change or edit the']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1.6.3'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "conf = SparkConf().setAppName(\"appName\")\n",
    "sc = SparkContext(conf=conf)\n",
    "rdd = sc.textFile(\"/data/mr/wordcount/input/\")\n",
    "print(rdd.take(10))\n",
    "sc.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.context.SparkContext object at 0x7fa0e4f5a208>\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function #python 3 support\n",
    "print(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23 items\r\n",
      "-rw-r--r--   3 hdfs hdfs       5542 2018-08-16 06:43 /data/spark/books.xml\r\n",
      "-rw-r--r--   3 hdfs hdfs   41125386 2018-12-14 15:01 /data/spark/btd2.json\r\n",
      "-rw-r--r--   3 hdfs hdfs        597 2018-08-16 06:43 /data/spark/episodes.avro\r\n",
      "-rw-r--r--   3 hdfs hdfs        240 2018-08-16 06:43 /data/spark/full_user.avsc\r\n",
      "drwxr-xr-x   - hdfs hdfs          0 2018-08-16 06:43 /data/spark/graphx\r\n",
      "-rw-r--r--   3 hdfs hdfs         72 2018-08-16 06:43 /data/spark/kmeans_data.txt\r\n",
      "-rw-r--r--   3 hdfs hdfs       5812 2018-08-16 06:43 /data/spark/kv1.txt\r\n",
      "drwxr-xr-x   - hdfs hdfs          0 2018-08-16 06:43 /data/spark/mllib\r\n",
      "-rw-r--r--   3 hdfs hdfs     972009 2018-08-16 06:43 /data/spark/mysql-connector-java-5.1.36-bin.jar\r\n",
      "drwxr-xr-x   - hdfs hdfs          0 2018-08-16 06:43 /data/spark/pb\r\n",
      "-rw-r--r--   3 hdfs hdfs         73 2018-08-16 06:43 /data/spark/people.json\r\n",
      "-rw-r--r--   3 hdfs hdfs         32 2018-08-16 06:43 /data/spark/people.txt\r\n",
      "drwxr-xr-x   - hdfs hdfs          0 2018-08-16 06:43 /data/spark/project\r\n",
      "-rw-r--r--   3 hdfs hdfs       3363 2018-08-16 06:43 /data/spark/pyspark-graphframes.ipynb\r\n",
      "-rw-r--r--   3 hdfs hdfs         68 2018-08-16 06:43 /data/spark/sample.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs        800 2018-08-16 06:43 /data/spark/spark_streaming_ex.py\r\n",
      "-rw-r--r--   3 hdfs hdfs         73 2018-08-16 06:43 /data/spark/spark_streaming_ex.sh\r\n",
      "-rw-r--r--   3 hdfs hdfs   10766276 2018-08-16 06:43 /data/spark/stocks.json\r\n",
      "-rw-r--r--   3 hdfs hdfs        146 2018-08-16 06:43 /data/spark/temps.csv\r\n",
      "-rw-r--r--   3 hdfs hdfs        645 2018-08-16 06:43 /data/spark/uncommon_words.py\r\n",
      "-rw-r--r--   3 hdfs hdfs        185 2018-08-16 06:43 /data/spark/user.avsc\r\n",
      "-rw-r--r--   3 hdfs hdfs        334 2018-08-16 06:43 /data/spark/users.avro\r\n",
      "-rw-r--r--   3 hdfs hdfs        615 2018-08-16 06:43 /data/spark/users.parquet\r\n"
     ]
    }
   ],
   "source": [
    "# Check the folder for files in hdfs\n",
    "!hadoop fs -ls /data/spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotly imports\n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "import pandas as pd\n",
    "import requests\n",
    "requests.packages.urllib3.disable_warnings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/hdp/current/spark-client/python/lib/pyspark.zip/pyspark/sql/context.py:478: UserWarning:\n",
      "\n",
      "jsonFile is deprecated. Use read.json() instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyspark.sql.dataframe.DataFrame'>\n",
      "root\n",
      " |-- Bike #: string (nullable = true)\n",
      " |-- Duration: string (nullable = true)\n",
      " |-- End Date: string (nullable = true)\n",
      " |-- End Station: string (nullable = true)\n",
      " |-- End Terminal: string (nullable = true)\n",
      " |-- Start Date: string (nullable = true)\n",
      " |-- Start Station: string (nullable = true)\n",
      " |-- Start Terminal: string (nullable = true)\n",
      " |-- Subscription Type: string (nullable = true)\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Zip Code: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "btd = sqlContext.jsonFile(\"/data/spark/btd2.json\")\n",
    "print(type(btd))\n",
    "btd.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Bike #='520', Duration='63', End Date='8/29/13 14:14', End Station='South Van Ness at Market', End Terminal='66', Start Date='8/29/13 14:13', Start Station='South Van Ness at Market', Start Terminal='66', Subscription Type='Subscriber', Trip ID='4576', Zip Code='94127'),\n",
       " Row(Bike #='661', Duration='70', End Date='8/29/13 14:43', End Station='San Jose City Hall', End Terminal='10', Start Date='8/29/13 14:42', Start Station='San Jose City Hall', Start Terminal='10', Subscription Type='Subscriber', Trip ID='4607', Zip Code='95138'),\n",
       " Row(Bike #='48', Duration='71', End Date='8/29/13 10:17', End Station='Mountain View City Hall', End Terminal='27', Start Date='8/29/13 10:16', Start Station='Mountain View City Hall', Start Terminal='27', Subscription Type='Subscriber', Trip ID='4130', Zip Code='97214')]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check few records\n",
    "btd.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Register it as table so that we run the query\n",
    "sqlContext.registerDataFrameAsTable(btd, \"bay_area_bike\")\n",
    "df2 = sqlContext.sql(\"SELECT Duration as d1 from bay_area_bike where Duration < 100\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "553"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the counts. Helps in seeing if the data is all well\n",
    "df2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the data to be plotted\n",
    "data = [go.Histogram(x=df2.toPandas()['d1'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not that this requires you to signup  with plotly using https://plot.ly/api_signup\n",
    "And save the credentials using \n",
    "\n",
    "    mkdir ~/.plotly\n",
    "    nano ~/.plotly/.credentials\n",
    "    \n",
    "Copy paste the value that shows up in https://plot.ly/settings/api#/ in this format:\n",
    "\n",
    "    {\n",
    "        \"username\": \"<Your User Name>\",\n",
    "        \"api_key\": \"<Your API key>\",\n",
    "        \"proxy_username\": \"\",\n",
    "        \"proxy_password\": \"\",\n",
    "        \"stream_ids\": []\n",
    "    }\n",
    "\n",
    "\n",
    "See https://plot.ly/python/getting-started/#initialization-for-online-plotting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~sandeepgiri/7.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "py.iplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For rest, please follow:\n",
    "    \n",
    "    https://plot.ly/python/apache-spark/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
